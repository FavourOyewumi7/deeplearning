{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import os\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\user\\OneDrive\\Documents\\code\\face-mask-detector\\face-mask-detector\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(os.path.join(path, '*//*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of files are 1376\n"
     ]
    }
   ],
   "source": [
    "print('Total no of files are {}'.format(len(images)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dropout, Dense, MaxPooling2D\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cols , img_rows =28,28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(trainX[59999])\n",
    "trainY[59999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    train_Y = to_categorical(trainY, num_classes)\n",
    "    test_Y = to_categorical(testY, num_classes)\n",
    "    \n",
    "    train_X = trainX.reshape(trainX.shape[0], img_cols, img_rows, 1)\n",
    "    test_X = testX.reshape(testX.shape[0], img_cols, img_rows, 1)\n",
    "    \n",
    "    train_X = train_X.astype(\"float32\") / 255.0\n",
    "    test_X = test_X.astype(\"float32\") / 255.0\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch = 24\n",
    "epoch =20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.add(Conv2D(24, strides = (2,2),kernel_size =(3,3), activation =relu, input_shape =(img_rows, img_cols,1)))\n",
    "layers.add(Conv2D(24, activation =relu, kernel_size = (3,3)))\n",
    "layers.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "layers.add(Flatten())\n",
    "\n",
    "layers.add(Dense(128, activation =relu))\n",
    "layers.add(Dropout(0.5))\n",
    "layers.add(Dense(num_classes, activation = softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 13, 13, 24)        240       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 11, 11, 24)        5208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               76928     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 83,666\n",
      "Trainable params: 83,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.compile(loss=categorical_crossentropy, optimizer = 'SGD', metrics =[ 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 0.9370 - accuracy: 0.6630 - val_loss: 0.6008 - val_accuracy: 0.7820\n",
      "Epoch 2/20\n",
      "2500/2500 [==============================] - 39s 16ms/step - loss: 0.6061 - accuracy: 0.7793 - val_loss: 0.5254 - val_accuracy: 0.7977\n",
      "Epoch 3/20\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 0.5441 - accuracy: 0.8008 - val_loss: 0.4736 - val_accuracy: 0.8200\n",
      "Epoch 4/20\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 0.5059 - accuracy: 0.8157 - val_loss: 0.4470 - val_accuracy: 0.8335\n",
      "Epoch 5/20\n",
      "2500/2500 [==============================] - 40s 16ms/step - loss: 0.4811 - accuracy: 0.8249 - val_loss: 0.4365 - val_accuracy: 0.8350\n",
      "Epoch 6/20\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 0.4600 - accuracy: 0.8311 - val_loss: 0.4219 - val_accuracy: 0.8397\n",
      "Epoch 7/20\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 0.4422 - accuracy: 0.8383 - val_loss: 0.4036 - val_accuracy: 0.8504\n",
      "Epoch 8/20\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 0.4297 - accuracy: 0.8447 - val_loss: 0.3929 - val_accuracy: 0.8543\n",
      "Epoch 9/20\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 0.4155 - accuracy: 0.8488 - val_loss: 0.3838 - val_accuracy: 0.8582\n",
      "Epoch 10/20\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 0.4058 - accuracy: 0.8521 - val_loss: 0.3706 - val_accuracy: 0.8644\n",
      "Epoch 11/20\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 0.3979 - accuracy: 0.8552 - val_loss: 0.3663 - val_accuracy: 0.8659 loss: 0.3980 - accuracy -\n",
      "Epoch 12/20\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 0.3913 - accuracy: 0.8554 - val_loss: 0.3732 - val_accuracy: 0.8614\n",
      "Epoch 13/20\n",
      "2500/2500 [==============================] - 40s 16ms/step - loss: 0.3841 - accuracy: 0.8603 - val_loss: 0.3610 - val_accuracy: 0.8689\n",
      "Epoch 14/20\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 0.3738 - accuracy: 0.8636 - val_loss: 0.3562 - val_accuracy: 0.8684\n",
      "Epoch 15/20\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 0.3696 - accuracy: 0.8648 - val_loss: 0.3501 - val_accuracy: 0.8701\n",
      "Epoch 16/20\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 0.3645 - accuracy: 0.8672 - val_loss: 0.3443 - val_accuracy: 0.8756\n",
      "Epoch 17/20\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 0.3586 - accuracy: 0.8687 - val_loss: 0.3436 - val_accuracy: 0.8739\n",
      "Epoch 18/20\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 0.3559 - accuracy: 0.8695 - val_loss: 0.3480 - val_accuracy: 0.8713\n",
      "Epoch 19/20\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 0.3503 - accuracy: 0.8721 - val_loss: 0.3412 - val_accuracy: 0.8758\n",
      "Epoch 20/20\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 0.3441 - accuracy: 0.8734 - val_loss: 0.3381 - val_accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb8252b130>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.fit(train_X, train_Y,  batch_size =batch, epochs =epoch, validation_data = (test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = layers.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "fad = np.argmax(vals, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.83      0.83      0.83      1000\n",
      "     trouser       0.99      0.96      0.98      1000\n",
      "    pullover       0.79      0.83      0.81      1000\n",
      "       dress       0.84      0.91      0.88      1000\n",
      "        coat       0.79      0.78      0.79      1000\n",
      "      sandal       0.97      0.97      0.97      1000\n",
      "       shirt       0.69      0.60      0.65      1000\n",
      "     sneaker       0.92      0.96      0.94      1000\n",
      "         bag       0.96      0.98      0.97      1000\n",
      "  ankle boot       0.97      0.93      0.95      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_Y.argmax(axis=1), fad,\n",
    "\ttarget_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
